{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Denoising Diffusion Probabilistic Models with MedNIST Dataset\n",
    "\n",
    "This tutorial illustrates how to use MONAI for training a denoising diffusion probabilistic model (DDPM)[1] to create\n",
    "synthetic 2D images.\n",
    "\n",
    "[1] - Ho et al. \"Denoising Diffusion Probabilistic Models\" https://arxiv.org/abs/2006.11239\n",
    "\n",
    "TODO: Add Open in Colab\n",
    "\n",
    "## Setup environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[pillow, tqdm, einops]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai import transforms\n",
    "from monai.apps import MedNISTDataset\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.utils import first, set_determinism\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TODO: Add right import reference after deployed\n",
    "from generative.networks.nets import DiffusionModelUNet\n",
    "from generative.schedulers import DDPMScheduler\n",
    "\n",
    "print_config()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup data directory\n",
    "\n",
    "You can specify a directory with the MONAI_DATA_DIRECTORY environment variable.\n",
    "\n",
    "This allows you to save results and reuse downloads.\n",
    "\n",
    "If not specified a temporary directory will be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set deterministic training for reproducibility"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "set_determinism(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup MedNIST Dataset and training and validation dataloaders\n",
    "In this tutorial, we will train our models on the MedNIST dataset available on MONAI\n",
    "(https://docs.monai.io/en/stable/apps.html#monai.apps.MedNISTDataset). In order to train faster, we will select just\n",
    "one of the available classes (\"Hand\"), resulting in a training set with 7999 2D images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = MedNISTDataset(root_dir=root_dir, section=\"training\", download=True, progress=False, seed=0)\n",
    "train_datalist = [{\"image\": item[\"image\"]} for item in train_data.data if item[\"class_name\"] == \"Hand\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we use transforms to augment the training dataset:\n",
    "\n",
    "1. `LoadImaged` loads the hands images from files.\n",
    "1. `EnsureChannelFirstd` ensures the original data to construct \"channel first\" shape.\n",
    "1. `ScaleIntensityRanged` extracts intensity range [0, 255] and scales to [0, 1].\n",
    "1. `RandAffined` efficiently performs rotate, scale, shear, translate, etc. together based on PyTorch affine transform."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        transforms.RandAffined(\n",
    "            keys=[\"image\"],\n",
    "            rotate_range=[(-np.pi / 36, np.pi / 36), (-np.pi / 36, np.pi / 36)],\n",
    "            translate_range=[(-1, 1), (-1, 1)],\n",
    "            scale_range=[(-0.05, 0.05), (-0.05, 0.05)],\n",
    "            spatial_size=[64, 64],\n",
    "            padding_mode=\"zeros\",\n",
    "            prob=0.5,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "train_ds = CacheDataset(data=train_datalist, transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_data = MedNISTDataset(root_dir=root_dir, section=\"validation\", download=True, progress=False, seed=0)\n",
    "val_datalist = [{\"image\": item[\"image\"]} for item in train_data.data if item[\"class_name\"] == \"Hand\"]\n",
    "val_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\"]),\n",
    "        transforms.EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        transforms.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "    ]\n",
    ")\n",
    "val_ds = CacheDataset(data=val_datalist, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualisation of the training images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_data = first(train_loader)\n",
    "print(f\"batch shape: {check_data['image'].shape}\")\n",
    "image_visualisation = torch.cat(\n",
    "    [check_data[\"image\"][0, 0], check_data[\"image\"][1, 0], check_data[\"image\"][2, 0], check_data[\"image\"][3, 0]], dim=1\n",
    ")\n",
    "plt.figure(\"training images\", (12, 6))\n",
    "plt.imshow(image_visualisation, vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define network, scheduler and optimizer\n",
    "At this step, we instantiate the MONAI components to create a DDPM, the UNET and the noise scheduler. We are using\n",
    "the original DDPM scheduler containing 1000 timesteps in its Markov chain, and a 2D UNET with attention mechanisms\n",
    "in the 2nd and 3rd levels, each with 1 attention head."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = DiffusionModelUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    model_channels=64,\n",
    "    attention_resolutions=[2, 4],\n",
    "    num_res_blocks=1,\n",
    "    channel_mult=[1, 2, 2],\n",
    "    num_heads=1,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=2.5e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model training\n",
    "Here, we are training our model for 50 epochs (training time: ~20 minutes)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "val_interval = 5\n",
    "epoch_loss_list = []\n",
    "val_epoch_loss_list = []\n",
    "\n",
    "total_start = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), ncols=70)\n",
    "    progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for step, batch in progress_bar:\n",
    "        images = batch[\"image\"].to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Randomly select the timesteps to be used for the minibacth\n",
    "        timesteps = torch.randint(0, scheduler.num_train_timesteps, (images.shape[0],), device=device).long()\n",
    "\n",
    "        # Add noise to the minibatch images with intensity defined by the scheduler and timesteps\n",
    "        noise = torch.randn_like(images).to(device)\n",
    "        noisy_image = scheduler.add_noise(original_samples=images, noise=noise, timesteps=timesteps)\n",
    "\n",
    "        # In this example, we are parametrising our DDPM to learn the added noise (epsilon).\n",
    "        # For this reason, we are using our network to predict the added noise and then using L2 loss to predict\n",
    "        # its performance.\n",
    "        noise_pred = model(x=noisy_image, timesteps=timesteps)\n",
    "        loss = F.mse_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": epoch_loss / (step + 1),\n",
    "            }\n",
    "        )\n",
    "    epoch_loss_list.append(epoch_loss / (step + 1))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        for step, batch in enumerate(val_loader):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            timesteps = torch.randint(0, scheduler.num_train_timesteps, (images.shape[0],), device=device).long()\n",
    "            noise = torch.randn_like(images).to(device)\n",
    "            with torch.no_grad():\n",
    "                noisy_image = scheduler.add_noise(original_samples=images, noise=noise, timesteps=timesteps)\n",
    "                noise_pred = model(x=noisy_image, timesteps=timesteps)\n",
    "                val_loss = F.l1_loss(noise_pred.float(), noise.float())\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"val_loss\": val_epoch_loss / (step + 1),\n",
    "                }\n",
    "            )\n",
    "        val_epoch_loss_list.append(val_epoch_loss / (step + 1))\n",
    "\n",
    "        # Sampling image during training\n",
    "        image = torch.randn((1, 1, 64, 64))\n",
    "        image = image.to(device)\n",
    "        scheduler.set_timesteps(num_inference_steps=1000)\n",
    "        for t in scheduler.timesteps:\n",
    "            # 1. predict noise model_output\n",
    "            with torch.no_grad():\n",
    "                model_output = model(image, torch.Tensor((t,)).to(device))\n",
    "            # 2. compute previous image: x_t -> x_t-1\n",
    "            image, _ = scheduler.step(model_output, t, image)\n",
    "\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(image[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "        plt.tight_layout()\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "print(f\"train completed, total time: {total_time}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learning curves"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-v0_8\")\n",
    "plt.title(\"Learning Curves\", fontsize=20)\n",
    "plt.plot(np.linspace(1, n_epochs, n_epochs), epoch_loss_list, color=\"C0\", linewidth=2.0, label=\"Train\")\n",
    "plt.plot(\n",
    "    np.linspace(val_interval, n_epochs, int(n_epochs / val_interval)),\n",
    "    val_epoch_loss_list,\n",
    "    color=\"C1\",\n",
    "    linewidth=2.0,\n",
    "    label=\"Validation\",\n",
    ")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.xlabel(\"Epochs\", fontsize=16)\n",
    "plt.ylabel(\"Loss\", fontsize=16)\n",
    "plt.legend(prop={\"size\": 14})\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plotting sampling process along DDPM's Markov chain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "image = torch.randn(\n",
    "    (1, 1, 64, 64),\n",
    ")\n",
    "image = image.to(device)\n",
    "scheduler.set_timesteps(num_inference_steps=1000)\n",
    "\n",
    "intermediary = []\n",
    "for t in tqdm(scheduler.timesteps, ncols=70):\n",
    "    # 1. predict noise model_output\n",
    "    with torch.no_grad():\n",
    "        model_output = model(image, torch.Tensor((t,)).to(device))\n",
    "\n",
    "    # 2. compute previous image: x_t -> x_t-1\n",
    "    image, _ = scheduler.step(model_output, t, image)\n",
    "    if t % 100 == 0:\n",
    "        intermediary.append(image)\n",
    "\n",
    "chain = torch.cat(intermediary, dim=-1)\n",
    "plt.style.use(\"default\")\n",
    "plt.imshow(chain[0, 0].cpu(), vmin=0, vmax=1, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup data directory\n",
    "\n",
    "Remove directory if a temporary was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}